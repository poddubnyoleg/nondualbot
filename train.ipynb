{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poddubnyoleg/nondualbot/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bGc0Vcfy2zQJ",
        "colab_type": "code",
        "outputId": "6f8526df-369c-4f66-e750-866577bc88df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import keras.backend as K\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zxZbSUTb4lTk",
        "colab_type": "code",
        "outputId": "9e2ccf3f-6113-481d-f081-38219d08d4a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8JWl2n_n6LVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/My Drive/nondualbot/i_am_that.txt', 'r') \n",
        "data = file.read() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zwJjADvv7vzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3aec7984-4d6c-4d20-ef04-14d81e39c8b3"
      },
      "cell_type": "code",
      "source": [
        "data[:100]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'That which permeates all, which nothing transcends and which, like the universal space around us, fi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "edNZraxrSXoB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(data)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pSO_sRT_Sq4o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "85de2c36-6770-49b8-b699-ccb20a0651b0"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "n_chars = len(data)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  988168\n",
            "Total Vocab:  55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G6xQoIj3S2M7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each chunk of data [seq_length] we take one-hot-encoded dataX array and dataY array (same but shifted +1)"
      ]
    },
    {
      "metadata": {
        "id": "d5ShWWBXSyPh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "overlapping_length = 30\n",
        "dataX = []\n",
        "dataY = []\n",
        "cur_pos = 0\n",
        "while cur_pos<n_chars-seq_length-1:\n",
        "  seq_input = np_utils.to_categorical([char_to_int[char] for char in data[cur_pos:cur_pos + seq_length]], num_classes=n_vocab)\n",
        "  seq_output = np_utils.to_categorical(char_to_int[data[cur_pos + seq_length]],num_classes=n_vocab)\n",
        "  dataX.append(seq_input)\n",
        "  dataY.append(seq_output)\n",
        "\n",
        "  cur_pos+=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lb2h7ht9Yz-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7116cbbf-fa2b-43c5-de2f-f069ae300044"
      },
      "cell_type": "code",
      "source": [
        "X = np.reshape(dataX, (len(dataX), seq_length, n_vocab))\n",
        "print(X.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(197614, 100, 55)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3BzYkU9JTk0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab0a9f23-60f7-4684-ac40-26738937a8cd"
      },
      "cell_type": "code",
      "source": [
        "y = np.reshape(dataY, (len(dataY), n_vocab))\n",
        "print(y.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(197614, 55)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OjiTElmhZU9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c90ce4e3-0d31-4c49-b448-69e6f5201ba8"
      },
      "cell_type": "code",
      "source": [
        "X.shape[1], X.shape[2], y.shape[1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 55, 55)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "qdJx7TCHUniR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "9f20cc95-d3a5-4122-ee35-e5ac74d10f6c"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 100, 256)          319488    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 55)                14135     \n",
            "=================================================================\n",
            "Total params: 858,935\n",
            "Trainable params: 858,935\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i9G0Bo1CZOYy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath=\"/content/drive/My Drive/nondualbot/best_current_weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a76QE1vrZRkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3247
        },
        "outputId": "9f535411-97d3-4039-edff-c93872fcbe56"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=100, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.6280\n",
            "\n",
            "Epoch 00001: loss improved from 0.62872 to 0.62796, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 2/100\n",
            "197614/197614 [==============================] - 621s 3ms/step - loss: 0.6217\n",
            "\n",
            "Epoch 00002: loss improved from 0.62796 to 0.62174, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 3/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.6208\n",
            "\n",
            "Epoch 00003: loss improved from 0.62174 to 0.62081, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 4/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.6147\n",
            "\n",
            "Epoch 00004: loss improved from 0.62081 to 0.61467, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 5/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.6139\n",
            "\n",
            "Epoch 00005: loss improved from 0.61467 to 0.61387, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 6/100\n",
            "197614/197614 [==============================] - 621s 3ms/step - loss: 0.6118\n",
            "\n",
            "Epoch 00006: loss improved from 0.61387 to 0.61180, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 7/100\n",
            "197614/197614 [==============================] - 623s 3ms/step - loss: 0.6084\n",
            "\n",
            "Epoch 00007: loss improved from 0.61180 to 0.60844, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 8/100\n",
            "197614/197614 [==============================] - 626s 3ms/step - loss: 0.6037\n",
            "\n",
            "Epoch 00008: loss improved from 0.60844 to 0.60372, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 9/100\n",
            "197614/197614 [==============================] - 626s 3ms/step - loss: 0.6036\n",
            "\n",
            "Epoch 00009: loss improved from 0.60372 to 0.60362, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 10/100\n",
            "197614/197614 [==============================] - 624s 3ms/step - loss: 0.6019\n",
            "\n",
            "Epoch 00010: loss improved from 0.60362 to 0.60190, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 11/100\n",
            "197614/197614 [==============================] - 618s 3ms/step - loss: 0.5983\n",
            "\n",
            "Epoch 00011: loss improved from 0.60190 to 0.59831, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 12/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5987\n",
            "\n",
            "Epoch 00012: loss did not improve from 0.59831\n",
            "Epoch 13/100\n",
            "197614/197614 [==============================] - 620s 3ms/step - loss: 0.5952\n",
            "\n",
            "Epoch 00013: loss improved from 0.59831 to 0.59525, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 14/100\n",
            "197614/197614 [==============================] - 619s 3ms/step - loss: 0.5910\n",
            "\n",
            "Epoch 00014: loss improved from 0.59525 to 0.59103, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 15/100\n",
            "197614/197614 [==============================] - 620s 3ms/step - loss: 0.5889\n",
            "\n",
            "Epoch 00015: loss improved from 0.59103 to 0.58891, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 16/100\n",
            "197614/197614 [==============================] - 623s 3ms/step - loss: 0.5863\n",
            "\n",
            "Epoch 00016: loss improved from 0.58891 to 0.58628, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 17/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5826\n",
            "\n",
            "Epoch 00017: loss improved from 0.58628 to 0.58257, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 18/100\n",
            "197614/197614 [==============================] - 623s 3ms/step - loss: 0.5781\n",
            "\n",
            "Epoch 00018: loss improved from 0.58257 to 0.57811, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 19/100\n",
            "197614/197614 [==============================] - 621s 3ms/step - loss: 0.5783\n",
            "\n",
            "Epoch 00019: loss did not improve from 0.57811\n",
            "Epoch 20/100\n",
            "197614/197614 [==============================] - 621s 3ms/step - loss: 0.5783\n",
            "\n",
            "Epoch 00020: loss did not improve from 0.57811\n",
            "Epoch 21/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5770\n",
            "\n",
            "Epoch 00021: loss improved from 0.57811 to 0.57699, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 22/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5705\n",
            "\n",
            "Epoch 00022: loss improved from 0.57699 to 0.57052, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 23/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5716\n",
            "\n",
            "Epoch 00023: loss did not improve from 0.57052\n",
            "Epoch 24/100\n",
            "197614/197614 [==============================] - 621s 3ms/step - loss: 0.5693\n",
            "\n",
            "Epoch 00024: loss improved from 0.57052 to 0.56933, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 25/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5674\n",
            "\n",
            "Epoch 00025: loss improved from 0.56933 to 0.56736, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 26/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5663\n",
            "\n",
            "Epoch 00026: loss improved from 0.56736 to 0.56630, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 27/100\n",
            "197614/197614 [==============================] - 621s 3ms/step - loss: 0.5603\n",
            "\n",
            "Epoch 00027: loss improved from 0.56630 to 0.56026, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 28/100\n",
            "197614/197614 [==============================] - 621s 3ms/step - loss: 0.5557\n",
            "\n",
            "Epoch 00028: loss improved from 0.56026 to 0.55569, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 29/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5591\n",
            "\n",
            "Epoch 00029: loss did not improve from 0.55569\n",
            "Epoch 30/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5545\n",
            "\n",
            "Epoch 00030: loss improved from 0.55569 to 0.55449, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 31/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5525\n",
            "\n",
            "Epoch 00031: loss improved from 0.55449 to 0.55251, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 32/100\n",
            "197614/197614 [==============================] - 620s 3ms/step - loss: 0.5514\n",
            "\n",
            "Epoch 00032: loss improved from 0.55251 to 0.55140, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 33/100\n",
            "197614/197614 [==============================] - 619s 3ms/step - loss: 0.5506\n",
            "\n",
            "Epoch 00033: loss improved from 0.55140 to 0.55057, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 34/100\n",
            "197614/197614 [==============================] - 620s 3ms/step - loss: 0.5434\n",
            "\n",
            "Epoch 00034: loss improved from 0.55057 to 0.54338, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 35/100\n",
            "197614/197614 [==============================] - 620s 3ms/step - loss: 0.5447\n",
            "\n",
            "Epoch 00035: loss did not improve from 0.54338\n",
            "Epoch 36/100\n",
            "197614/197614 [==============================] - 620s 3ms/step - loss: 0.5408\n",
            "\n",
            "Epoch 00036: loss improved from 0.54338 to 0.54085, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 37/100\n",
            "197614/197614 [==============================] - 620s 3ms/step - loss: 0.5379\n",
            "\n",
            "Epoch 00037: loss improved from 0.54085 to 0.53793, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 38/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5473\n",
            "\n",
            "Epoch 00038: loss did not improve from 0.53793\n",
            "Epoch 39/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5356\n",
            "\n",
            "Epoch 00039: loss improved from 0.53793 to 0.53565, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 40/100\n",
            "197614/197614 [==============================] - 621s 3ms/step - loss: 0.5348\n",
            "\n",
            "Epoch 00040: loss improved from 0.53565 to 0.53480, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 41/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5294\n",
            "\n",
            "Epoch 00041: loss improved from 0.53480 to 0.52940, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 42/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5318\n",
            "\n",
            "Epoch 00042: loss did not improve from 0.52940\n",
            "Epoch 43/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5302\n",
            "\n",
            "Epoch 00043: loss did not improve from 0.52940\n",
            "Epoch 44/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5294\n",
            "\n",
            "Epoch 00044: loss did not improve from 0.52940\n",
            "Epoch 45/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5197\n",
            "\n",
            "Epoch 00045: loss improved from 0.52940 to 0.51968, saving model to /content/drive/My Drive/nondualbot/best_current_weights.hdf5\n",
            "Epoch 46/100\n",
            "197614/197614 [==============================] - 622s 3ms/step - loss: 0.5226\n",
            "\n",
            "Epoch 00046: loss did not improve from 0.51968\n",
            "Epoch 47/100\n",
            "197614/197614 [==============================] - 620s 3ms/step - loss: 0.5218\n",
            "\n",
            "Epoch 00047: loss did not improve from 0.51968\n",
            "Epoch 48/100\n",
            "131840/197614 [===================>..........] - ETA: 3:26 - loss: 0.5072"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8mj5q7TvGk6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load the network weights\n",
        "filename = \"/content/drive/My Drive/nondualbot/best_current_weights.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f0UrZXwm2lwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8469cac6-ef1f-4eb1-b0dc-49793d15afbb"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(X, y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98807/98807 [==============================] - 779s 8ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04695190974103574"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "XL8cNhyR2fsg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c484fb8b-9427-41a9-ddd5-451fb18b082b"
      },
      "cell_type": "code",
      "source": [
        "(np.array([[1,2,3]]*3)).shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "zOP7fzC71Ucf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "302334bb-dcbd-4e69-e116-cf8f8e9d66ae"
      },
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9999523e-01, 2.0463224e-06, 9.3156482e-16, 2.3285486e-06,\n",
              "        3.1841680e-07, 1.1315500e-36, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "        4.9429824e-36, 1.0919554e-22, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3220731e-36,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "        9.8703578e-27, 0.0000000e+00, 0.0000000e+00, 3.1538452e-32,\n",
              "        2.3943110e-30, 7.3807023e-17, 2.3995033e-16, 5.8587215e-16,\n",
              "        3.7597976e-14, 2.5189800e-11, 7.6478038e-16, 5.2172624e-11,\n",
              "        9.8157481e-15, 2.1217654e-10, 3.3302342e-25, 1.8736244e-16,\n",
              "        2.3516426e-13, 2.5805555e-15, 7.1146422e-12, 3.6919934e-15,\n",
              "        9.9358932e-21, 7.0374929e-28, 3.0649214e-13, 2.7722578e-11,\n",
              "        1.3439056e-13, 7.3349047e-15, 3.3891350e-18, 9.7494195e-18,\n",
              "        1.6992857e-22, 7.3972104e-12, 1.7295703e-31]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "6ZD7FuFmZXHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "b2e036ff-5853-497f-e521-c3e1a07456b3"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# pick a random seed\n",
        "#start = np.random.randint(0, len(dataX)-1)\n",
        "#pattern = dataX[start]\n",
        "#print(''.join([int_to_char[value] for value in pattern_flat]))\n",
        "question = 'Who am I?'\n",
        "pattern = np_utils.to_categorical([char_to_int[char] for char in question], num_classes=n_vocab)\n",
        "pattern = np.append(np.zeros(shape=(max(seq_length-pattern.shape[0],0), n_vocab)), pattern, axis=0)\n",
        "\n",
        "print(question)\n",
        "\n",
        "# generate characters\n",
        "for i in range(150):\n",
        "\n",
        "  prediction = model.predict(np.reshape(pattern, (1, pattern.shape[0], pattern.shape[1])), verbose=0)\n",
        "  \n",
        "  index = np.argmax(prediction)#np.random.choice(len(prediction[0]), p=prediction[0])#\n",
        "  result = int_to_char[index]\n",
        "  sys.stdout.write(result)\n",
        "  pattern = np.append(pattern, [np_utils.to_categorical(index,num_classes=n_vocab)], axis=0)\n",
        "  pattern = pattern[1:len(pattern)]\n",
        "  #print(\"\\nDone.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-147b47b56ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Who am I?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np_utils' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "O0Ejib5PAEAJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "ed6d8d02-c6de-45d4-f4ae-68499bc23b01"
      },
      "cell_type": "code",
      "source": [
        "def sample_prediction(prediction):\n",
        "  \"\"\"Get rand index from preds based on its prob distribution.\n",
        "\n",
        "  Params\n",
        "  ——\n",
        "  prediction (array (array)): array of length 1 containing array of probs that sums to 1\n",
        "\n",
        "  Returns\n",
        "  ——-\n",
        "  rnd_idx (int): random index from prediction[0]\n",
        "\n",
        "  Notes\n",
        "  —–\n",
        "  Helps to solve problem of repeated outputs.\n",
        "\n",
        "  len(prediction) = 1\n",
        "  len(prediction[0]) >> 1\n",
        "  \"\"\"\n",
        "  X = prediction[0] # sum(X) is approx 1\n",
        "  rnd_idx = np.random.choice(len(X), p=X)\n",
        "  return rnd_idx\n",
        "\n",
        "for i in range(num_outputs):\n",
        "x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "x = x / float(n_vocab)\n",
        "prediction = model.predict(x, verbose=0)\n",
        "#index = numpy.argmax(prediction)\n",
        "# per Gustavo’s suggestion, we should not use argmax here\n",
        "index = sample_prediction(prediction)\n",
        "result = int_to_char[index]\n",
        "#seq_in = [int_to_char[value] for value in pattern]\n",
        "# not sure why seq_in was here\n",
        "sys.stdout.write(result)\n",
        "pattern.append(index)\n",
        "pattern = pattern[1:len(pattern)]\n",
        "print “\\nDone.”"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ded. And yet in India every holy man has his tiger, lion, leopard or antelope skin to sit on. Maybe \n",
            "e e\n",
            "\n",
            "which makes the changeful possible. But he cannot give you the conviction. It must come with your ow\n",
            "   \n",
            "\n",
            " all suffering self-created? Yes, as long as there is a separate self to create it. In the end you k\n",
            "o o\n",
            "\n",
            "aper with All the horrors going on. Since the world is yourself, how can you explain such misbehavio\n",
            "r r\n",
            "\n",
            "scious of not having a body. I see you smoking Exactly so. You see me smoking. Find out for yourself\n",
            "h h\n",
            "\n",
            "r butter. Do it correctly and assiduously and the result is sure to come. How can the absolute be th\n",
            "   \n",
            "\n",
            " me how it is done. In selfawareness I see the body and the mind moved by causes beyond my control. \n",
            "e e\n",
            "\n",
            "es. But a general memory of well-being is there. There is a difference in feeling when we say I was \n",
            "e e\n",
            "\n",
            "from the experience to the experiencer and realise the full import of the only true statement you ca\n",
            "   \n",
            "\n",
            "ce. Be devoted to your goal -- and devotion to him who can guide you will follow. If your desire and\n",
            "c c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oVhh9O8OPJ_b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pattern = dataX[start]\n",
        "#pattern = np.append(pattern, np_utils.to_categorical(index,num_classes=n_vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lChG5UQGlewY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "70e55f41-d38d-42c9-faa8-c3b052ac648c"
      },
      "cell_type": "code",
      "source": [
        "np.append(pattern, [np_utils.to_categorical(index,num_classes=n_vocab)], axis=0)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "4ghdt5Z3mhhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3904acd3-afc1-4e70-d68d-0818c7792194"
      },
      "cell_type": "code",
      "source": [
        "patte"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "DfwWaffxnHuG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7eb2936-9a7f-4a50-cd88-e44d5008a656"
      },
      "cell_type": "code",
      "source": [
        "np.argmax(dataY[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "40kQZZqnA_T8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "11c81b77-8bf1-4ef8-def8-3c2c59fd51ab"
      },
      "cell_type": "code",
      "source": [
        "dataY[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "nKovml72BAbC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}